[
  {
    "id": 3,
    "title": "Case Study 4: Boston Housing & German Credit Data Analysis",
    "date": "2024-11-05",
    "description": "<p>This project involved analyzing the Boston Housing and German Credit datasets using machine learning techniques. The goal was to apply and compare predictive models, including CART (Classification and Regression Trees) and logistic regression, to evaluate model performance and generalization capability.</p>",
    "methodology": "<ul>\r\n<li data-start=\"641\" data-end=\"1272\">\r\n<p data-start=\"643\" data-end=\"667\"><strong data-start=\"643\" data-end=\"667\">Boston Housing Data:</strong></p>\r\n<ul data-start=\"670\" data-end=\"1272\">\r\n<li data-start=\"670\" data-end=\"760\">Utilized CART (Classification and Regression Tree) to predict median home values (medv).</li>\r\n<li data-start=\"763\" data-end=\"819\">Split the data into 90% training and 10% testing sets.</li>\r\n<li data-start=\"822\" data-end=\"911\">Visualized the regression tree using the 'prp' function to display splits at each node.</li>\r\n<li data-start=\"914\" data-end=\"1017\">Calculated in-sample MSE of 17.21 and out-of-sample MSE of 27.39, highlighting potential overfitting.</li>\r\n<li data-start=\"1020\" data-end=\"1170\">Compared CART model performance against a linear regression model, where the linear model's in-sample MSE was 21.53 and out-of-sample MSE was 25.54.</li>\r\n<li data-start=\"1173\" data-end=\"1272\">The CART model demonstrated better fit for non-linear relationships compared to the linear model.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"1274\" data-end=\"1884\">\r\n<p data-start=\"1276\" data-end=\"1299\"><strong data-start=\"1276\" data-end=\"1299\">German Credit Data:</strong></p>\r\n<ul data-start=\"1302\" data-end=\"1884\">\r\n<li data-start=\"1302\" data-end=\"1419\">Processed data by converting categorical variables to factors and splitting into 80% training and 20% testing sets.</li>\r\n<li data-start=\"1422\" data-end=\"1528\">Built a classification tree model with an additional cost matrix to prioritize reducing false negatives.</li>\r\n<li data-start=\"1531\" data-end=\"1627\">Compared the classification tree to a logistic regression model using misclassification costs.</li>\r\n<li data-start=\"1630\" data-end=\"1765\">The classification tree showed an out-of-sample misclassification cost of 0.6827, compared to the logistic regression model's 0.6471.</li>\r\n<li data-start=\"1768\" data-end=\"1884\">The CART model prioritized reducing false negatives, demonstrating its utility in identifying high-risk customers.</li>\r\n</ul>\r\n</li>\r\n</ul>",
    "thumbnail": "assets/images/Screenshot_2025-03-10_153552_1741646201.png",
    "liveDemo": "",
    "repoUrl": "",
    "reportPdf": "",
    "technologies": [
      "R",
      "CART (Classification and Regression Trees)",
      "Linear Regression",
      "Logistic Regression",
      "Data Visualization"
    ],
    "overview": {
      "story": "<p>The project focused on analyzing the Boston Housing and German Credit datasets to gain insights into housing market trends and credit risk assessment. The Boston Housing dataset aimed to predict median home values using predictive models, while the German Credit dataset focused on evaluating customer creditworthiness using classification techniques. The project explored the effectiveness of CART (Classification and Regression Trees) and logistic regression models in handling both regression and classification tasks.</p>",
      "collectedData": "<ul>\r\n<li data-start=\"574\" data-end=\"752\"><strong data-start=\"576\" data-end=\"603\">Boston Housing Dataset:</strong> Sourced from the MASS library in R, containing features such as crime rate, number of rooms, and socioeconomic status to predict median home values.</li>\r\n<li data-start=\"753\" data-end=\"1048\"><strong data-start=\"755\" data-end=\"781\">German Credit Dataset:</strong> Included customer demographics, financial attributes, and payment history to predict the likelihood of defaulting on credit payments. The dataset was preprocessed by converting categorical variables into factors and splitting the data into training and testing sets.</li>\r\n</ul>",
      "conclusions": "<ul>\r\n<li data-start=\"1078\" data-end=\"1300\">The CART model effectively captured non-linear relationships in the Boston Housing dataset, achieving an in-sample MSE of 17.21 and an out-of-sample MSE of 27.39. However, the discrepancy suggested potential overfitting.</li>\r\n<li data-start=\"1301\" data-end=\"1491\">The linear regression model had a higher in-sample MSE of 21.53 and a better out-of-sample MSE of 25.54, indicating a more generalized performance but less adaptability to non-linear data.</li>\r\n<li data-start=\"1492\" data-end=\"1686\">In the German Credit analysis, the classification tree model with a cost-sensitive approach prioritized minimizing false negatives, achieving an out-of-sample misclassification cost of 0.6827.</li>\r\n<li data-start=\"1687\" data-end=\"1929\">The logistic regression model performed similarly, with an out-of-sample misclassification cost of 0.6471, but the classification tree provided better control over misclassification types, proving advantageous for financial risk management.</li>\r\n</ul>"
    },
    "codeFiles": [],
    "resources": [
      {
        "name": "Case Study 4 Code ",
        "category": "Code Samples",
        "file_path": "assets/files/CaseStudy4_1741646201.R",
        "file_type": "application/octet-stream"
      },
      {
        "name": "Case Study 4 Report ",
        "category": "Reports",
        "file_path": "assets/files/CaseStudy4_1741646201.pdf",
        "file_type": "application/pdf"
      }
    ]
  },
  {
    "id": 4,
    "title": "Obesity Analysis and Prediction Using Machine Learning",
    "date": "2024-12-01",
    "description": "<p>This project analyzes obesity trends and contributing factors using machine learning models. It employs&nbsp;<strong data-start=\"527\" data-end=\"586\">Linear Regression, Regression Trees, and Random Forests</strong>&nbsp;to predict weight based on demographic and lifestyle factors. The dataset is sourced from the&nbsp;<strong data-start=\"681\" data-end=\"716\">UCI Machine Learning Repository</strong>.</p>",
    "methodology": "<ul>\r\n<li data-start=\"754\" data-end=\"992\">\r\n<p data-start=\"757\" data-end=\"788\"><strong data-start=\"757\" data-end=\"786\">Data Preprocessing &amp; EDA:</strong></p>\r\n<ul data-start=\"792\" data-end=\"992\">\r\n<li data-start=\"792\" data-end=\"886\">Analyzed key variables such as Age, Height, and Weight using histograms and scatter plots.</li>\r\n<li data-start=\"890\" data-end=\"992\">Identified patterns in the dataset, including right-skewed distributions and correlation clusters.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"994\" data-end=\"1214\">\r\n<p data-start=\"997\" data-end=\"1021\"><strong data-start=\"997\" data-end=\"1019\">Linear Regression:</strong></p>\r\n<ul data-start=\"1025\" data-end=\"1214\">\r\n<li data-start=\"1025\" data-end=\"1081\">Built a stepwise regression model to predict Weight.</li>\r\n<li data-start=\"1085\" data-end=\"1137\">Removed non-significant predictors (SMOKE, SCC).</li>\r\n<li data-start=\"1141\" data-end=\"1214\">Achieved an&nbsp;<strong data-start=\"1155\" data-end=\"1177\">R&sup2; value of 96.29%</strong>, indicating strong predictability.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"1216\" data-end=\"1429\">\r\n<p data-start=\"1219\" data-end=\"1241\"><strong data-start=\"1219\" data-end=\"1239\">Regression Tree:</strong></p>\r\n<ul data-start=\"1245\" data-end=\"1429\">\r\n<li data-start=\"1245\" data-end=\"1302\">Developed a decision tree to classify obesity levels.</li>\r\n<li data-start=\"1306\" data-end=\"1381\">Height and obesity category (NObeyesdad) were the strongest predictors.</li>\r\n<li data-start=\"1385\" data-end=\"1429\">Performed pruning to reduce overfitting.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"1431\" data-end=\"1718\">\r\n<p data-start=\"1434\" data-end=\"1460\"><strong data-start=\"1434\" data-end=\"1458\">Random Forest Model:</strong></p>\r\n<ul data-start=\"1464\" data-end=\"1718\">\r\n<li data-start=\"1464\" data-end=\"1520\">Built an ensemble model with&nbsp;<strong data-start=\"1495\" data-end=\"1517\">100 decision trees</strong>.</li>\r\n<li data-start=\"1524\" data-end=\"1626\">Feature importance analysis showed&nbsp;<strong data-start=\"1561\" data-end=\"1603\">NObeyesdad, Height, and Family History</strong>&nbsp;as top contributors.</li>\r\n<li data-start=\"1630\" data-end=\"1718\">The model had high accuracy but risked overfitting, requiring hyperparameter tuning.</li>\r\n</ul>\r\n</li>\r\n</ul>",
    "thumbnail": "assets/images/obesity_report_photo_1741646439.png",
    "liveDemo": "",
    "repoUrl": "",
    "reportPdf": "",
    "technologies": [
      "R",
      "Random Forest",
      "Linear Regression",
      "Decision Trees",
      "Data Visualization",
      "Machine Learning"
    ],
    "overview": {
      "story": "<p>Obesity is a growing epidemic influenced by multiple demographic and lifestyle factors. Using data-driven methods, this study explores how different features contribute to an individual's weight and obesity classification. The goal is to develop predictive models that can identify key contributors to obesity levels.</p>",
      "collectedData": "<ul>\r\n<li data-start=\"2933\" data-end=\"3048\"><strong data-start=\"2935\" data-end=\"2947\">Dataset:</strong>&nbsp;<strong data-start=\"2948\" data-end=\"3046\">UCI Machine Learning Repository - Obesity Levels Based on Eating Habits and Physical Condition</strong></li>\r\n<li data-start=\"3049\" data-end=\"3162\"><strong data-start=\"3051\" data-end=\"3068\">17 Variables:</strong>&nbsp;Includes Age, Gender, Height, Weight, Family History, Physical Activity, and Eating Habits.</li>\r\n<li data-start=\"3163\" data-end=\"3360\"><strong data-start=\"3165\" data-end=\"3182\">Key Insights:</strong>\r\n<ul data-start=\"3187\" data-end=\"3360\">\r\n<li data-start=\"3187\" data-end=\"3269\">The average weight in the dataset is&nbsp;<strong data-start=\"3226\" data-end=\"3234\">83kg</strong>, ranging from&nbsp;<strong data-start=\"3249\" data-end=\"3266\">39kg to 173kg</strong>.</li>\r\n<li data-start=\"3272\" data-end=\"3360\"><strong data-start=\"3274\" data-end=\"3347\">Height and obesity category (NObeyesdad) are the strongest predictors</strong> of weight.</li>\r\n</ul>\r\n</li>\r\n</ul>",
      "conclusions": "<ul>\r\n<li data-start=\"3397\" data-end=\"3485\"><strong data-start=\"3399\" data-end=\"3435\">Linear Regression performed best</strong>, achieving an&nbsp;<strong data-start=\"3450\" data-end=\"3482\">out-of-sample error of 23.85</strong>.</li>\r\n<li data-start=\"3486\" data-end=\"3592\"><strong data-start=\"3488\" data-end=\"3541\">Regression Tree showed structured decision-making</strong>, but pruning was necessary to avoid overfitting.</li>\r\n<li data-start=\"3593\" data-end=\"3659\"><strong data-start=\"3595\" data-end=\"3632\">Random Forest was highly accurate</strong>, but risked overfitting.</li>\r\n<li data-start=\"3660\" data-end=\"3764\"><strong data-start=\"3662\" data-end=\"3678\">Future Work:</strong> Hyperparameter tuning and cross-validation could further improve prediction accuracy.</li>\r\n</ul>"
    },
    "codeFiles": [],
    "resources": [
      {
        "name": "obesity_code ",
        "category": "Code Samples",
        "file_path": "assets/files/main3_1741646439.R",
        "file_type": "application/octet-stream"
      },
      {
        "name": "obesity_dataset",
        "category": "Datasets",
        "file_path": "assets/files/obesity_1741646439.csv",
        "file_type": "text/csv"
      },
      {
        "name": "obesity_report",
        "category": "",
        "file_path": "assets/files/FinalDraft_1741646439.docx",
        "file_type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
      }
    ]
  },
  {
    "id": 5,
    "title": "Simulation Analysis of Driver\u2019s License Facility Using Simio",
    "date": "2024-12-01",
    "description": "<p>This project involved simulating a driver's license facility using Simio to analyze server utilization, system performance, and the impact of proposed modifications on exam processing times. The goal was to optimize the facility's operations by evaluating different exam scheduling scenarios and routing strategies.</p>",
    "methodology": "<ul>\r\n<li data-start=\"566\" data-end=\"860\">\r\n<ul>\r\n<li data-start=\"566\" data-end=\"860\">\r\n<p data-start=\"569\" data-end=\"595\"><strong data-start=\"569\" data-end=\"595\">Current Configuration:</strong></p>\r\n<ul data-start=\"599\" data-end=\"860\">\r\n<li data-start=\"599\" data-end=\"749\">Simulated the facility's current operations with server utilization metrics for check-in, manual exams, computerized exams, and check-out processes.</li>\r\n<li data-start=\"753\" data-end=\"860\">Collected baseline data over 25 replications, each running for 1000 hours with a 500-hour warm-up period.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"862\" data-end=\"1299\">\r\n<p data-start=\"865\" data-end=\"892\">Simio, Simulation Modeling, Statistical Analysis, Optimization<strong data-start=\"865\" data-end=\"892\">Proposed Modifications:</strong></p>\r\n<ul data-start=\"896\" data-end=\"1299\">\r\n<li data-start=\"896\" data-end=\"988\"><strong data-start=\"898\" data-end=\"913\">Proposed A:</strong> Applied exponentially distributed exam times with Random.Exponential(8.8).</li>\r\n<li data-start=\"992\" data-end=\"1174\"><strong data-start=\"994\" data-end=\"1009\">Proposed B:</strong> Implemented reduced variance using triangular and uniform distributions:\r\n<ul data-start=\"1088\" data-end=\"1174\">\r\n<li data-start=\"1088\" data-end=\"1129\">Manual: Random.Triangular(6, 8.8, 11.6)</li>\r\n<li data-start=\"1135\" data-end=\"1174\">Computerized: Random.Uniform(6, 11.6)</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"1178\" data-end=\"1299\"><strong data-start=\"1180\" data-end=\"1195\">Proposed C:</strong> Combined reduced variance with a 70% allocation to the computerized exam kiosk using Selection Weights.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"1301\" data-end=\"1509\">\r\n<p data-start=\"1304\" data-end=\"1328\"><strong data-start=\"1304\" data-end=\"1328\">Performance Metrics:</strong></p>\r\n<ul data-start=\"1332\" data-end=\"1509\">\r\n<li data-start=\"1332\" data-end=\"1385\">Server utilization rates for each processing stage.</li>\r\n<li data-start=\"1389\" data-end=\"1433\">Average number of customers in the system.</li>\r\n<li data-start=\"1437\" data-end=\"1509\">Average time spent in the system with confidence interval half-widths.</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n</ul>",
    "thumbnail": "assets/images/Screenshot_2025-03-10_160633_1741648256.png",
    "liveDemo": "",
    "repoUrl": "",
    "reportPdf": "",
    "technologies": [
      "Simio",
      "Simulation Modeling",
      "Statistical Analysis",
      "Optimization"
    ],
    "overview": {
      "story": "<p>The driver's license facility faced challenges with balancing manual and computerized exam processing times. The project aimed to enhance customer flow and reduce waiting times through advanced simulation techniques. By testing different configurations in Simio, the study provided insights into how distribution changes and optimized routing could improve operational efficiency.</p>",
      "collectedData": "<ul>\r\n<li data-start=\"2026\" data-end=\"2111\"><strong data-start=\"2028\" data-end=\"2054\">Simulation Parameters:</strong> 25 replications, 1000-hour runs with a 500-hour warm-up.</li>\r\n<li data-start=\"2112\" data-end=\"2303\"><strong data-start=\"2114\" data-end=\"2138\">Distribution Models:</strong>\r\n<ul data-start=\"2141\" data-end=\"2303\">\r\n<li data-start=\"2141\" data-end=\"2209\">Exponential, Triangular, and Uniform distributions for exam times.</li>\r\n<li data-start=\"2212\" data-end=\"2303\">Selection Weights applied to route 70% of customers to computerized kiosks in Proposed C.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"2304\" data-end=\"2606\"><strong data-start=\"2306\" data-end=\"2330\">Performance Metrics:</strong>\r\n<ul data-start=\"2333\" data-end=\"2606\">\r\n<li data-start=\"2333\" data-end=\"2494\">Server Utilization:\r\n<ul data-start=\"2359\" data-end=\"2494\">\r\n<li data-start=\"2359\" data-end=\"2375\">Check-In: ~83%</li>\r\n<li data-start=\"2380\" data-end=\"2399\">Manual Exam: ~73%</li>\r\n<li data-start=\"2404\" data-end=\"2472\">Computerized Exam: N/A in current, optimized in proposed scenarios</li>\r\n<li data-start=\"2477\" data-end=\"2494\">Check-Out: ~75%</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"2497\" data-end=\"2606\">System Performance:\r\n<ul data-start=\"2523\" data-end=\"2606\">\r\n<li data-start=\"2523\" data-end=\"2546\">Number in System: ~11</li>\r\n<li data-start=\"2551\" data-end=\"2606\">Time in System: ~69 minutes (varied across scenarios)</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n</ul>",
      "conclusions": "<ul>\r\n<li data-start=\"2636\" data-end=\"2728\"><strong data-start=\"2638\" data-end=\"2653\">Proposed A:</strong> Showed marginal improvement but increased variability in processing times.</li>\r\n<li data-start=\"2729\" data-end=\"2834\"><strong data-start=\"2731\" data-end=\"2746\">Proposed B:</strong> Reduced variability effectively, enhancing the stability of server utilization metrics.</li>\r\n<li data-start=\"2835\" data-end=\"2950\"><strong data-start=\"2837\" data-end=\"2852\">Proposed C:</strong> The best performing scenario, achieving balanced load distribution and improved processing times.</li>\r\n<li data-start=\"2951\" data-end=\"3122\">The use of a 70% routing strategy to the computerized exam kiosks significantly reduced manual exam bottlenecks, demonstrating the value of targeted operational changes.</li>\r\n</ul>"
    },
    "codeFiles": [],
    "resources": [
      {
        "name": "assignment_6_dl",
        "category": "Reference Materials",
        "file_path": "assets/files/Assignment6_1741648256.spfx",
        "file_type": "application/octet-stream"
      }
    ]
  },
  {
    "id": 6,
    "title": "Healthcare Clinic Simulation Analysis Utilizing Simio",
    "date": "2024-12-15",
    "description": "<p>This project involved simulating a healthcare clinic using Simio to analyze system capacity under varying patient arrival rates. The goal was to evaluate the clinic's performance with increased patient load and the impact of introducing a new patient type with a specific treatment pathway.</p>",
    "methodology": "<ul>\r\n<li data-start=\"528\" data-end=\"859\">\r\n<p data-start=\"531\" data-end=\"560\"><strong data-start=\"531\" data-end=\"560\">Base Model Configuration:</strong></p>\r\n<ul data-start=\"564\" data-end=\"859\">\r\n<li data-start=\"564\" data-end=\"746\">Simulated the healthcare clinic's operations with predefined service times and capacities for each process (e.g., Registration, Triage, XRay, MRI, Treatment, Lab, EKG, Accounting).</li>\r\n<li data-start=\"750\" data-end=\"859\">Used random triangular distributions to model service times, reflecting variability in processing patients.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"861\" data-end=\"1208\">\r\n<p data-start=\"864\" data-end=\"886\"><strong data-start=\"864\" data-end=\"886\">Scenario Analysis:</strong></p>\r\n<ul data-start=\"890\" data-end=\"1208\">\r\n<li data-start=\"890\" data-end=\"988\">Evaluated the clinic's ability to handle increased patient arrival rates of +5%, +10%, and +15%.</li>\r\n<li data-start=\"992\" data-end=\"1110\">Analyzed system performance metrics, including average time in the system and waiting times at each service station.</li>\r\n<li data-start=\"1114\" data-end=\"1208\">Conducted 100 replications per scenario, each running for 12 hours without a warm-up period.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"1210\" data-end=\"1489\">\r\n<p data-start=\"1213\" data-end=\"1246\"><strong data-start=\"1213\" data-end=\"1246\">New Patient Type Integration:</strong></p>\r\n<ul data-start=\"1250\" data-end=\"1489\">\r\n<li data-start=\"1250\" data-end=\"1383\">Introduced \"LabAndTreatmentPatients\" with a specific routing schedule: Registration, Lab, Treatment, and Accounting before exiting.</li>\r\n<li data-start=\"1387\" data-end=\"1489\">Assessed system capacity with the new patient type under all four scenarios (Base, +5%, +10%, +15%).</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"1491\" data-end=\"1647\">\r\n<p data-start=\"1494\" data-end=\"1518\"><strong data-start=\"1494\" data-end=\"1518\">Performance Metrics:</strong></p>\r\n<ul data-start=\"1522\" data-end=\"1647\">\r\n<li data-start=\"1522\" data-end=\"1567\">Average time in the system by patient type.</li>\r\n<li data-start=\"1571\" data-end=\"1603\">Waiting times at each station.</li>\r\n<li data-start=\"1607\" data-end=\"1647\">Capacity utilization for each process.</li>\r\n</ul>\r\n</li>\r\n</ul>",
    "thumbnail": "assets/images/Screenshot_2025-03-10_162746_1741649294.png",
    "liveDemo": "",
    "repoUrl": "",
    "reportPdf": "",
    "technologies": [
      "Simio",
      "Simulation Modeling",
      "System Capacity Analysis",
      "Statistical Performance Evaluation"
    ],
    "overview": {
      "story": "<p>The healthcare clinic aimed to improve patient flow and reduce waiting times while preparing for potential increases in patient arrivals. The simulation provided insights into the clinic's current capacity and the potential impact of adding new patient types. By evaluating different arrival rate scenarios, the study helped identify bottlenecks and guide staffing or process adjustments to maintain service quality.</p>",
      "collectedData": "<ul>\r\n<li data-start=\"2226\" data-end=\"2571\">\r\n<p data-start=\"2228\" data-end=\"2259\"><strong data-start=\"2228\" data-end=\"2259\">Service Time Distributions:</strong></p>\r\n<ul data-start=\"2262\" data-end=\"2571\">\r\n<li data-start=\"2262\" data-end=\"2302\">Registration: Random.Triangular(1,2,3)</li>\r\n<li data-start=\"2305\" data-end=\"2339\">Triage: Random.Triangular(3,5,7)</li>\r\n<li data-start=\"2342\" data-end=\"2376\">XRay: Random.Triangular(8,10,12)</li>\r\n<li data-start=\"2379\" data-end=\"2413\">MRI: Random.Triangular(14,18,22)</li>\r\n<li data-start=\"2416\" data-end=\"2457\">Treatment: Random.Triangular(7,10.5,14)</li>\r\n<li data-start=\"2460\" data-end=\"2493\">Lab: Random.Triangular(6,10,14)</li>\r\n<li data-start=\"2496\" data-end=\"2530\">EKG: Random.Triangular(20,25,30)</li>\r\n<li data-start=\"2533\" data-end=\"2571\">Accounting: Random.Triangular(2,5,8)</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"2573\" data-end=\"2792\">\r\n<p data-start=\"2575\" data-end=\"2601\"><strong data-start=\"2575\" data-end=\"2601\">Patient Arrival Rates:</strong></p>\r\n<ul data-start=\"2604\" data-end=\"2792\">\r\n<li data-start=\"2604\" data-end=\"2698\">Base Case: Mean inter-arrival times ranging from 3 to 30 minutes, depending on patient type.</li>\r\n<li data-start=\"2701\" data-end=\"2792\">Increased patient arrival rates reduced the average time between arrivals proportionally.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"2794\" data-end=\"3019\">\r\n<p data-start=\"2796\" data-end=\"2819\"><strong data-start=\"2796\" data-end=\"2819\">System Performance:</strong></p>\r\n<ul data-start=\"2822\" data-end=\"3019\">\r\n<li data-start=\"2822\" data-end=\"2905\">Analyzed the system's ability to handle increased loads without excessive delays.</li>\r\n<li data-start=\"2908\" data-end=\"3019\">Identified potential process improvements, especially for high-traffic areas like Registration and Treatment.</li>\r\n</ul>\r\n</li>\r\n</ul>",
      "conclusions": "<ul>\r\n<li data-start=\"3049\" data-end=\"3147\">The system could handle a +5% increase in patient arrivals with minimal impact on waiting times.</li>\r\n<li data-start=\"3148\" data-end=\"3268\">At +10% and +15% increases, significant delays occurred, particularly in high-demand processes like Treatment and Lab.</li>\r\n<li data-start=\"3269\" data-end=\"3394\">The introduction of \"LabAndTreatmentPatients\" required additional capacity, particularly in the Lab and Treatment stations.</li>\r\n<li data-start=\"3395\" data-end=\"3498\">Recommended adding capacity or optimizing patient routing to maintain performance under higher loads.</li>\r\n</ul>"
    },
    "codeFiles": [],
    "resources": [
      {
        "name": "healthcare",
        "category": "",
        "file_path": "assets/files/Assignment8.1_1741649294.spfx",
        "file_type": "application/octet-stream"
      }
    ]
  },
  {
    "id": 7,
    "title": "Clustering Analysis and Market Basket Analysis Using R",
    "date": "2024-11-19",
    "description": "<p>This project utilized the Iris dataset for clustering analysis using K-means and hierarchical methods and performed market basket analysis on grocery transaction data using association rule mining. The goal was to uncover patterns in customer purchasing behavior and identify meaningful clusters within the Iris dataset.</p>",
    "methodology": "<h4 data-start=\"575\" data-end=\"603\">1. Clustering Analysis:</h4>\r\n<ul data-start=\"604\" data-end=\"1179\">\r\n<li data-start=\"604\" data-end=\"679\"><strong data-start=\"606\" data-end=\"618\">Dataset:</strong> The Iris dataset with a random sample of 90% of data points.</li>\r\n<li data-start=\"680\" data-end=\"869\"><strong data-start=\"682\" data-end=\"705\">K-means Clustering:</strong>\r\n<ul data-start=\"708\" data-end=\"869\">\r\n<li data-start=\"708\" data-end=\"763\">Applied K-means clustering with a 5-cluster solution.</li>\r\n<li data-start=\"766\" data-end=\"869\">Visualized cluster centers and distribution using <code data-start=\"818\" data-end=\"831\">plotcluster</code> and analyzed cluster characteristics.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"870\" data-end=\"1179\"><strong data-start=\"872\" data-end=\"900\">Hierarchical Clustering:</strong>\r\n<ul data-start=\"903\" data-end=\"1179\">\r\n<li data-start=\"903\" data-end=\"986\">Utilized Ward's method to calculate Euclidean distances and produce a dendrogram.</li>\r\n<li data-start=\"989\" data-end=\"1082\">Analyzed clustering behavior with 2 and 3 cuts to understand how the data groups naturally.</li>\r\n<li data-start=\"1085\" data-end=\"1179\">Found that clustering by size produced groups representing large, medium, and small flowers.</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h4 data-start=\"1181\" data-end=\"1212\">2. Market Basket Analysis:</h4>\r\n<ul data-start=\"1213\" data-end=\"1887\">\r\n<li data-start=\"1213\" data-end=\"1287\"><strong data-start=\"1215\" data-end=\"1227\">Dataset:</strong> Groceries data containing 9,835 transactions and 169 items.</li>\r\n<li data-start=\"1288\" data-end=\"1486\"><strong data-start=\"1290\" data-end=\"1311\">Data Exploration:</strong>\r\n<ul data-start=\"1314\" data-end=\"1486\">\r\n<li data-start=\"1314\" data-end=\"1405\">Found \"whole milk\" as the most frequently purchased item, present in 25% of transactions.</li>\r\n<li data-start=\"1408\" data-end=\"1486\">The average transaction included 4.4 items, with the maximum being 32 items.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"1487\" data-end=\"1887\"><strong data-start=\"1489\" data-end=\"1517\">Association Rule Mining:</strong>\r\n<ul data-start=\"1520\" data-end=\"1887\">\r\n<li data-start=\"1520\" data-end=\"1621\">Generated association rules with Apriori algorithm under varying support and confidence thresholds.</li>\r\n<li data-start=\"1624\" data-end=\"1703\">Initial settings (0.1% support, 1% confidence) resulted in over 40,000 rules.</li>\r\n<li data-start=\"1706\" data-end=\"1796\">Adjusted parameters to 2.5% support and 10% confidence, reducing to 75 meaningful rules.</li>\r\n<li data-start=\"1799\" data-end=\"1887\">Evaluated rules based on lift and confidence to identify strong purchase correlations.</li>\r\n</ul>\r\n</li>\r\n</ul>",
    "thumbnail": "assets/images/Screenshot_2025-03-10_165243_1741650781.png",
    "liveDemo": "",
    "repoUrl": "",
    "reportPdf": "",
    "technologies": [
      "R",
      "K-means Clustering",
      "Hierarchical Clustering",
      "Association Rule Mining",
      "Data Visualization"
    ],
    "overview": {
      "story": "<p>The project aimed to demonstrate clustering techniques on the Iris dataset and discover patterns in grocery shopping behavior through association rule mining. The clustering analysis helped visualize how flower species could be grouped based on physical attributes, while the market basket analysis identified frequent product pairings to enhance marketing strategies.</p>",
      "collectedData": "<ul>\r\n<li data-start=\"2421\" data-end=\"2686\">\r\n<p data-start=\"2423\" data-end=\"2447\"><strong data-start=\"2423\" data-end=\"2447\">Clustering Findings:</strong></p>\r\n<ul data-start=\"2450\" data-end=\"2686\">\r\n<li data-start=\"2450\" data-end=\"2534\">K-means analysis produced 5 distinct clusters with specific species distributions.</li>\r\n<li data-start=\"2537\" data-end=\"2686\">Hierarchical clustering revealed how the dataset could be split into larger or smaller groups, showing flexibility in interpreting cluster results.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"2688\" data-end=\"2964\">\r\n<p data-start=\"2690\" data-end=\"2717\"><strong data-start=\"2690\" data-end=\"2717\">Market Basket Analysis:</strong></p>\r\n<ul data-start=\"2720\" data-end=\"2964\">\r\n<li data-start=\"2720\" data-end=\"2836\">The strongest association rule found was between \"root vegetables\" and \"other vegetables,\" showing a lift of 2.25.</li>\r\n<li data-start=\"2839\" data-end=\"2964\">Rules indicated that buying specific items, like \"curd,\" increases the likelihood of purchasing \"whole milk\" by 1.92 times.</li>\r\n</ul>\r\n</li>\r\n</ul>",
      "conclusions": "<ul>\r\n<li data-start=\"2994\" data-end=\"3122\">Clustering analysis showed the Iris dataset could be effectively segmented by size, with clear groupings between flower types.</li>\r\n<li data-start=\"3123\" data-end=\"3287\">Market basket analysis revealed valuable insights for grocery retail, highlighting strong product affinities that could inform promotions or store layout designs.</li>\r\n<li data-start=\"3288\" data-end=\"3423\">The project demonstrated the effectiveness of clustering and association rule techniques in extracting actionable insights from data.</li>\r\n</ul>"
    },
    "codeFiles": [],
    "resources": [
      {
        "name": "case5",
        "category": "Code Samples",
        "file_path": "assets/files/Case5_1741650781.R",
        "file_type": "application/octet-stream"
      },
      {
        "name": "case5_report",
        "category": "Reports",
        "file_path": "assets/files/CaseStudy5_1741650781.docx",
        "file_type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
      }
    ]
  },
  {
    "id": 8,
    "title": "Accenture Data Analytics and Visualization",
    "date": "2025-03-17",
    "description": "<ul>\r\n<li data-start=\"198\" data-end=\"283\"><strong data-start=\"201\" data-end=\"232\">Data Cleaning &amp; Preparation</strong> &ndash; Handling and transforming raw data for analysis.</li>\r\n<li data-start=\"284\" data-end=\"367\"><strong data-start=\"287\" data-end=\"304\">Data Modeling</strong> &ndash; Identifying trends and insights using analytical techniques.</li>\r\n<li data-start=\"368\" data-end=\"452\"><strong data-start=\"371\" data-end=\"393\">Data Visualization</strong> &ndash; Creating dashboards and reports to communicate findings.</li>\r\n<li data-start=\"453\" data-end=\"537\"><strong data-start=\"456\" data-end=\"487\">Data-Driven Decision Making</strong> &ndash; Using insights to recommend business solutions.</li>\r\n</ul>\r\n<p>&nbsp;</p>",
    "methodology": "<ul>\r\n<li data-start=\"312\" data-end=\"470\">\r\n<p data-start=\"315\" data-end=\"348\"><strong data-start=\"315\" data-end=\"346\">Data Understanding &amp; Import</strong></p>\r\n<ul data-start=\"352\" data-end=\"470\">\r\n<li data-start=\"352\" data-end=\"396\">Obtain raw CSV data</li>\r\n<li data-start=\"400\" data-end=\"470\">Load the dataset into Python and Excel</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"472\" data-end=\"753\">\r\n<p data-start=\"475\" data-end=\"508\"><strong data-start=\"475\" data-end=\"506\">Data Cleaning &amp; Preparation</strong></p>\r\n<ul data-start=\"512\" data-end=\"753\">\r\n<li data-start=\"512\" data-end=\"560\">Identify missing values and inconsistencies.</li>\r\n<li data-start=\"564\" data-end=\"643\">Filter out unnecessary data using criteria&nbsp;</li>\r\n<li data-start=\"647\" data-end=\"708\">Removed rows based on null category</li>\r\n<li data-start=\"712\" data-end=\"753\">Remove duplicates and correct errors.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"755\" data-end=\"1034\">\r\n<p data-start=\"758\" data-end=\"794\"><strong data-start=\"758\" data-end=\"792\">Data Analysis &amp; Transformation</strong></p>\r\n<ul data-start=\"798\" data-end=\"1034\">\r\n<li data-start=\"798\" data-end=\"887\">Use <strong data-start=\"804\" data-end=\"845\">pivot tables, formulas, and filtering</strong> in Excel to segment and summarize data.</li>\r\n<li data-start=\"891\" data-end=\"960\">Perform calculations through Excel</li>\r\n<li data-start=\"964\" data-end=\"1034\">Identify popular content based upon content score</li>\r\n</ul>\r\n</li>\r\n</ul>",
    "thumbnail": "assets/images/Screenshot_2025-03-17_215123_1742273869.png",
    "liveDemo": "",
    "repoUrl": "",
    "reportPdf": "",
    "technologies": [],
    "overview": {
      "story": "<p data-start=\"218\" data-end=\"483\">Social Buzz was founded by two former engineers from a major social media company. They aimed to build a platform that prioritizes content over users by keeping interactions <strong data-start=\"392\" data-end=\"405\">anonymous</strong> and allowing <strong data-start=\"419\" data-end=\"442\">100+ reaction types</strong> beyond traditional likes and comments.</p>\r\n<p data-start=\"485\" data-end=\"860\">The platform has grown <strong data-start=\"508\" data-end=\"519\">rapidly</strong>, reaching <strong data-start=\"530\" data-end=\"561\">500M active users per month</strong> in the last five years. However, this growth has created challenges in <strong data-start=\"633\" data-end=\"686\">data management, scalability, and IPO preparation</strong>. Their vast, <strong data-start=\"700\" data-end=\"721\">unstructured data</strong> includes over <strong data-start=\"736\" data-end=\"778\">100,000 pieces of content posted daily</strong> (text, images, videos, GIFs), requiring <strong data-start=\"819\" data-end=\"847\">sophisticated technology</strong> to handle.</p>\r\n<p data-start=\"862\" data-end=\"968\">Despite never relying on third-party firms, they now seek <strong data-start=\"920\" data-end=\"942\">external expertise</strong> for three main reasons:</p>\r\n<ol data-start=\"969\" data-end=\"1244\">\r\n<li data-start=\"969\" data-end=\"1054\"><strong data-start=\"972\" data-end=\"991\">IPO Preparation</strong> &ndash; Ensuring a smooth transition to becoming a public company.</li>\r\n<li data-start=\"1055\" data-end=\"1142\"><strong data-start=\"1058\" data-end=\"1077\">Scaling Support</strong> &ndash; Addressing resource constraints while managing rapid growth.</li>\r\n<li data-start=\"1143\" data-end=\"1244\"><strong data-start=\"1146\" data-end=\"1173\">Big Data Best Practices</strong> &ndash; Learning from large corporations on managing vast amounts of data.</li>\r\n</ol>\r\n<p data-start=\"1246\" data-end=\"1338\">To start, Social Buzz has engaged an advisory firm for a <strong data-start=\"1303\" data-end=\"1322\">3-month project</strong>, focusing on:</p>\r\n<ul data-start=\"1339\" data-end=\"1595\">\r\n<li data-start=\"1339\" data-end=\"1426\"><strong data-start=\"1341\" data-end=\"1359\">Big Data Audit</strong> &ndash; Reviewing their data management and technology infrastructure.</li>\r\n<li data-start=\"1427\" data-end=\"1509\"><strong data-start=\"1429\" data-end=\"1445\">IPO Strategy</strong> &ndash; Providing recommendations for a successful public offering.</li>\r\n<li data-start=\"1510\" data-end=\"1595\"><strong data-start=\"1512\" data-end=\"1532\">Content Analysis</strong> &ndash; Identifying the <strong data-start=\"1551\" data-end=\"1592\">top 5 most popular content categories</strong>.</li>\r\n</ul>\r\n<p data-start=\"1597\" data-end=\"1772\" data-is-last-node=\"\" data-is-only-node=\"\">This engagement includes tasks like <strong data-start=\"1633\" data-end=\"1749\">SQL data extraction, data visualization, stress testing their technology, and consulting with past IPO companies</strong> to guide their growth.</p>",
      "collectedData": "<p data-start=\"81\" data-end=\"115\"><strong data-start=\"81\" data-end=\"113\">Content Data (<code data-start=\"97\" data-end=\"110\">Content.csv</code>)</strong></p>\r\n<ul data-start=\"119\" data-end=\"392\">\r\n<li data-start=\"119\" data-end=\"199\">Contains information about different types of content posted on Social Buzz.</li>\r\n<li data-start=\"203\" data-end=\"313\">Key columns: <code data-start=\"218\" data-end=\"230\">Content ID</code>, <code data-start=\"232\" data-end=\"238\">Type</code> (photo, video, etc.), and <code data-start=\"265\" data-end=\"275\">Category</code> (e.g., technology, food, studying).</li>\r\n<li data-start=\"317\" data-end=\"392\">Examples of categories: <strong data-start=\"343\" data-end=\"390\">Studying, Healthy Eating, Technology, Food.</strong></li>\r\n</ul>\r\n<p data-start=\"397\" data-end=\"435\"><strong data-start=\"397\" data-end=\"433\">Reactions Data (<code data-start=\"415\" data-end=\"430\">Reactions.csv</code>)</strong></p>\r\n<ul data-start=\"439\" data-end=\"686\">\r\n<li data-start=\"439\" data-end=\"524\">Captures user interactions with content, including reaction types and timestamps.</li>\r\n<li data-start=\"528\" data-end=\"605\">Key columns: <code data-start=\"543\" data-end=\"555\">Content ID</code>, <code data-start=\"557\" data-end=\"566\">User ID</code>, <code data-start=\"568\" data-end=\"574\">Type</code> (reaction type), <code data-start=\"592\" data-end=\"602\">Datetime</code>.</li>\r\n<li data-start=\"609\" data-end=\"686\">Reactions include <strong data-start=\"629\" data-end=\"669\">disgust, dislike, scared, interested</strong>, among others.</li>\r\n</ul>\r\n<p data-start=\"1071\" data-end=\"1113\"><strong data-start=\"1071\" data-end=\"1111\">Reaction Types (<code data-start=\"1089\" data-end=\"1108\">ReactionTypes.csv</code>)</strong></p>\r\n<ul data-start=\"1117\" data-end=\"1377\">\r\n<li data-start=\"1117\" data-end=\"1178\">Provides <strong data-start=\"1128\" data-end=\"1156\">sentiment classification</strong> for reaction types.</li>\r\n<li data-start=\"1182\" data-end=\"1291\">Sentiments are labeled as <strong data-start=\"1210\" data-end=\"1288\">positive (e.g., heart, want, interested) or negative (e.g., hate, disgust)</strong>.</li>\r\n<li data-start=\"1295\" data-end=\"1377\">Each reaction has an associated <strong data-start=\"1329\" data-end=\"1338\">score</strong> (e.g., <code data-start=\"1346\" data-end=\"1353\">heart</code> = 60, <code data-start=\"1360\" data-end=\"1369\">disgust</code> = 0).</li>\r\n</ul>",
      "conclusions": "<p data-start=\"1432\" data-end=\"1476\"><strong data-start=\"1432\" data-end=\"1474\">Top 5 Most Popular Content Categories:</strong></p>\r\n<ul data-start=\"1480\" data-end=\"1643\">\r\n<li data-start=\"1480\" data-end=\"1575\"><strong data-start=\"1482\" data-end=\"1536\">Animals, Science, Healthy Eating, Technology, Food</strong> receive the highest reaction scores.</li>\r\n<li data-start=\"1579\" data-end=\"1643\">These categories should be prioritized for content strategy.</li>\r\n</ul>\r\n<p data-start=\"1648\" data-end=\"1679\"><strong data-start=\"1648\" data-end=\"1677\">User Engagement Patterns:</strong></p>\r\n<ul data-start=\"1683\" data-end=\"1986\">\r\n<li data-start=\"1683\" data-end=\"1772\">Users react with a <strong data-start=\"1704\" data-end=\"1733\">diverse range of emotions</strong>, not just simple likes and dislikes.</li>\r\n<li data-start=\"1776\" data-end=\"1904\"><strong data-start=\"1778\" data-end=\"1902\">Positive reactions (e.g., \"heart,\" \"want,\" \"interested\") score higher than negative reactions (e.g., \"disgust,\" \"hate\").</strong></li>\r\n<li data-start=\"1908\" data-end=\"1986\">This suggests <strong data-start=\"1924\" data-end=\"1983\">engagement is more driven by positive sentiment content</strong>.</li>\r\n</ul>\r\n<p data-start=\"1991\" data-end=\"2024\"><strong data-start=\"1991\" data-end=\"2022\">Reaction Trends &amp; Insights:</strong></p>\r\n<ul data-start=\"2028\" data-end=\"2222\">\r\n<li data-start=\"2028\" data-end=\"2107\">The <strong data-start=\"2034\" data-end=\"2059\">Reaction Score metric</strong> helps quantify engagement beyond just counts.</li>\r\n<li data-start=\"2111\" data-end=\"2222\">Some categories consistently score <strong data-start=\"2148\" data-end=\"2169\">higher engagement</strong> based on <strong data-start=\"2179\" data-end=\"2219\">reaction type and sentiment analysis</strong>.</li>\r\n</ul>\r\n<p data-start=\"2227\" data-end=\"2263\"><strong data-start=\"2227\" data-end=\"2261\">Content Performance Takeaways:</strong></p>\r\n<ul data-start=\"2267\" data-end=\"2538\">\r\n<li data-start=\"2267\" data-end=\"2321\"><strong data-start=\"2269\" data-end=\"2296\">Photo and video content</strong> dominate the platform.</li>\r\n<li data-start=\"2325\" data-end=\"2430\">Categories that align with <strong data-start=\"2354\" data-end=\"2412\">emotional engagement (e.g., Animals, Food, Technology)</strong> perform better.</li>\r\n<li data-start=\"2434\" data-end=\"2538\"><strong data-start=\"2436\" data-end=\"2468\">Data-driven content curation</strong> can help <strong data-start=\"2478\" data-end=\"2535\">boost user engagement and trending content visibility</strong>.</li>\r\n</ul>"
    },
    "codeFiles": [],
    "resources": [
      {
        "name": "Accenture_Excel",
        "category": "Reference Materials",
        "file_path": "assets/files/reaction_finished_1742273869.csv",
        "file_type": "text/csv"
      }
    ]
  }
]