[
  {
    "id": 3,
    "title": "Case Study 4: Boston Housing & German Credit Data Analysis",
    "date": "2024-11-05",
    "description": "<p>This project involved analyzing the Boston Housing and German Credit datasets using machine learning techniques. The goal was to apply and compare predictive models, including CART (Classification and Regression Trees) and logistic regression, to evaluate model performance and generalization capability.</p>",
    "methodology": "<ul>\r\n<li data-start=\"641\" data-end=\"1272\">\r\n<p data-start=\"643\" data-end=\"667\"><strong data-start=\"643\" data-end=\"667\">Boston Housing Data:</strong></p>\r\n<ul data-start=\"670\" data-end=\"1272\">\r\n<li data-start=\"670\" data-end=\"760\">Utilized CART (Classification and Regression Tree) to predict median home values (medv).</li>\r\n<li data-start=\"763\" data-end=\"819\">Split the data into 90% training and 10% testing sets.</li>\r\n<li data-start=\"822\" data-end=\"911\">Visualized the regression tree using the 'prp' function to display splits at each node.</li>\r\n<li data-start=\"914\" data-end=\"1017\">Calculated in-sample MSE of 17.21 and out-of-sample MSE of 27.39, highlighting potential overfitting.</li>\r\n<li data-start=\"1020\" data-end=\"1170\">Compared CART model performance against a linear regression model, where the linear model's in-sample MSE was 21.53 and out-of-sample MSE was 25.54.</li>\r\n<li data-start=\"1173\" data-end=\"1272\">The CART model demonstrated better fit for non-linear relationships compared to the linear model.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"1274\" data-end=\"1884\">\r\n<p data-start=\"1276\" data-end=\"1299\"><strong data-start=\"1276\" data-end=\"1299\">German Credit Data:</strong></p>\r\n<ul data-start=\"1302\" data-end=\"1884\">\r\n<li data-start=\"1302\" data-end=\"1419\">Processed data by converting categorical variables to factors and splitting into 80% training and 20% testing sets.</li>\r\n<li data-start=\"1422\" data-end=\"1528\">Built a classification tree model with an additional cost matrix to prioritize reducing false negatives.</li>\r\n<li data-start=\"1531\" data-end=\"1627\">Compared the classification tree to a logistic regression model using misclassification costs.</li>\r\n<li data-start=\"1630\" data-end=\"1765\">The classification tree showed an out-of-sample misclassification cost of 0.6827, compared to the logistic regression model's 0.6471.</li>\r\n<li data-start=\"1768\" data-end=\"1884\">The CART model prioritized reducing false negatives, demonstrating its utility in identifying high-risk customers.</li>\r\n</ul>\r\n</li>\r\n</ul>",
    "thumbnail": "assets/images/Screenshot_2025-03-10_153552_1741646201.png",
    "liveDemo": "",
    "repoUrl": "",
    "reportPdf": "",
    "technologies": [
      "R",
      "CART (Classification and Regression Trees)",
      "Linear Regression",
      "Logistic Regression",
      "Data Visualization"
    ],
    "overview": {
      "story": "<p>The project focused on analyzing the Boston Housing and German Credit datasets to gain insights into housing market trends and credit risk assessment. The Boston Housing dataset aimed to predict median home values using predictive models, while the German Credit dataset focused on evaluating customer creditworthiness using classification techniques. The project explored the effectiveness of CART (Classification and Regression Trees) and logistic regression models in handling both regression and classification tasks.</p>",
      "collectedData": "<ul>\r\n<li data-start=\"574\" data-end=\"752\"><strong data-start=\"576\" data-end=\"603\">Boston Housing Dataset:</strong> Sourced from the MASS library in R, containing features such as crime rate, number of rooms, and socioeconomic status to predict median home values.</li>\r\n<li data-start=\"753\" data-end=\"1048\"><strong data-start=\"755\" data-end=\"781\">German Credit Dataset:</strong> Included customer demographics, financial attributes, and payment history to predict the likelihood of defaulting on credit payments. The dataset was preprocessed by converting categorical variables into factors and splitting the data into training and testing sets.</li>\r\n</ul>",
      "conclusions": "<ul>\r\n<li data-start=\"1078\" data-end=\"1300\">The CART model effectively captured non-linear relationships in the Boston Housing dataset, achieving an in-sample MSE of 17.21 and an out-of-sample MSE of 27.39. However, the discrepancy suggested potential overfitting.</li>\r\n<li data-start=\"1301\" data-end=\"1491\">The linear regression model had a higher in-sample MSE of 21.53 and a better out-of-sample MSE of 25.54, indicating a more generalized performance but less adaptability to non-linear data.</li>\r\n<li data-start=\"1492\" data-end=\"1686\">In the German Credit analysis, the classification tree model with a cost-sensitive approach prioritized minimizing false negatives, achieving an out-of-sample misclassification cost of 0.6827.</li>\r\n<li data-start=\"1687\" data-end=\"1929\">The logistic regression model performed similarly, with an out-of-sample misclassification cost of 0.6471, but the classification tree provided better control over misclassification types, proving advantageous for financial risk management.</li>\r\n</ul>"
    },
    "codeFiles": [],
    "resources": [
      {
        "name": "Case Study 4 Code ",
        "category": "Code Samples",
        "file_path": "assets/files/CaseStudy4_1741646201.R",
        "file_type": "application/octet-stream"
      },
      {
        "name": "Case Study 4 Report ",
        "category": "Reports",
        "file_path": "assets/files/CaseStudy4_1741646201.pdf",
        "file_type": "application/pdf"
      }
    ]
  },
  {
    "id": 4,
    "title": "Obesity Analysis and Prediction Using Machine Learning",
    "date": "2024-12-01",
    "description": "<p>This project analyzes obesity trends and contributing factors using machine learning models. It employs&nbsp;<strong data-start=\"527\" data-end=\"586\">Linear Regression, Regression Trees, and Random Forests</strong>&nbsp;to predict weight based on demographic and lifestyle factors. The dataset is sourced from the&nbsp;<strong data-start=\"681\" data-end=\"716\">UCI Machine Learning Repository</strong>.</p>",
    "methodology": "<ul>\r\n<li data-start=\"754\" data-end=\"992\">\r\n<p data-start=\"757\" data-end=\"788\"><strong data-start=\"757\" data-end=\"786\">Data Preprocessing &amp; EDA:</strong></p>\r\n<ul data-start=\"792\" data-end=\"992\">\r\n<li data-start=\"792\" data-end=\"886\">Analyzed key variables such as Age, Height, and Weight using histograms and scatter plots.</li>\r\n<li data-start=\"890\" data-end=\"992\">Identified patterns in the dataset, including right-skewed distributions and correlation clusters.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"994\" data-end=\"1214\">\r\n<p data-start=\"997\" data-end=\"1021\"><strong data-start=\"997\" data-end=\"1019\">Linear Regression:</strong></p>\r\n<ul data-start=\"1025\" data-end=\"1214\">\r\n<li data-start=\"1025\" data-end=\"1081\">Built a stepwise regression model to predict Weight.</li>\r\n<li data-start=\"1085\" data-end=\"1137\">Removed non-significant predictors (SMOKE, SCC).</li>\r\n<li data-start=\"1141\" data-end=\"1214\">Achieved an&nbsp;<strong data-start=\"1155\" data-end=\"1177\">R&sup2; value of 96.29%</strong>, indicating strong predictability.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"1216\" data-end=\"1429\">\r\n<p data-start=\"1219\" data-end=\"1241\"><strong data-start=\"1219\" data-end=\"1239\">Regression Tree:</strong></p>\r\n<ul data-start=\"1245\" data-end=\"1429\">\r\n<li data-start=\"1245\" data-end=\"1302\">Developed a decision tree to classify obesity levels.</li>\r\n<li data-start=\"1306\" data-end=\"1381\">Height and obesity category (NObeyesdad) were the strongest predictors.</li>\r\n<li data-start=\"1385\" data-end=\"1429\">Performed pruning to reduce overfitting.</li>\r\n</ul>\r\n</li>\r\n<li data-start=\"1431\" data-end=\"1718\">\r\n<p data-start=\"1434\" data-end=\"1460\"><strong data-start=\"1434\" data-end=\"1458\">Random Forest Model:</strong></p>\r\n<ul data-start=\"1464\" data-end=\"1718\">\r\n<li data-start=\"1464\" data-end=\"1520\">Built an ensemble model with&nbsp;<strong data-start=\"1495\" data-end=\"1517\">100 decision trees</strong>.</li>\r\n<li data-start=\"1524\" data-end=\"1626\">Feature importance analysis showed&nbsp;<strong data-start=\"1561\" data-end=\"1603\">NObeyesdad, Height, and Family History</strong>&nbsp;as top contributors.</li>\r\n<li data-start=\"1630\" data-end=\"1718\">The model had high accuracy but risked overfitting, requiring hyperparameter tuning.</li>\r\n</ul>\r\n</li>\r\n</ul>",
    "thumbnail": "assets/images/obesity_report_photo_1741646439.png",
    "liveDemo": "",
    "repoUrl": "",
    "reportPdf": "",
    "technologies": [
      "R",
      "Random Forest",
      "Linear Regression",
      "Decision Trees",
      "Data Visualization",
      "Machine Learning"
    ],
    "overview": {
      "story": "<p>Obesity is a growing epidemic influenced by multiple demographic and lifestyle factors. Using data-driven methods, this study explores how different features contribute to an individual's weight and obesity classification. The goal is to develop predictive models that can identify key contributors to obesity levels.</p>",
      "collectedData": "<ul>\r\n<li data-start=\"2933\" data-end=\"3048\"><strong data-start=\"2935\" data-end=\"2947\">Dataset:</strong>&nbsp;<strong data-start=\"2948\" data-end=\"3046\">UCI Machine Learning Repository - Obesity Levels Based on Eating Habits and Physical Condition</strong></li>\r\n<li data-start=\"3049\" data-end=\"3162\"><strong data-start=\"3051\" data-end=\"3068\">17 Variables:</strong>&nbsp;Includes Age, Gender, Height, Weight, Family History, Physical Activity, and Eating Habits.</li>\r\n<li data-start=\"3163\" data-end=\"3360\"><strong data-start=\"3165\" data-end=\"3182\">Key Insights:</strong>\r\n<ul data-start=\"3187\" data-end=\"3360\">\r\n<li data-start=\"3187\" data-end=\"3269\">The average weight in the dataset is&nbsp;<strong data-start=\"3226\" data-end=\"3234\">83kg</strong>, ranging from&nbsp;<strong data-start=\"3249\" data-end=\"3266\">39kg to 173kg</strong>.</li>\r\n<li data-start=\"3272\" data-end=\"3360\"><strong data-start=\"3274\" data-end=\"3347\">Height and obesity category (NObeyesdad) are the strongest predictors</strong> of weight.</li>\r\n</ul>\r\n</li>\r\n</ul>",
      "conclusions": "<ul>\r\n<li data-start=\"3397\" data-end=\"3485\"><strong data-start=\"3399\" data-end=\"3435\">Linear Regression performed best</strong>, achieving an&nbsp;<strong data-start=\"3450\" data-end=\"3482\">out-of-sample error of 23.85</strong>.</li>\r\n<li data-start=\"3486\" data-end=\"3592\"><strong data-start=\"3488\" data-end=\"3541\">Regression Tree showed structured decision-making</strong>, but pruning was necessary to avoid overfitting.</li>\r\n<li data-start=\"3593\" data-end=\"3659\"><strong data-start=\"3595\" data-end=\"3632\">Random Forest was highly accurate</strong>, but risked overfitting.</li>\r\n<li data-start=\"3660\" data-end=\"3764\"><strong data-start=\"3662\" data-end=\"3678\">Future Work:</strong> Hyperparameter tuning and cross-validation could further improve prediction accuracy.</li>\r\n</ul>"
    },
    "codeFiles": [],
    "resources": [
      {
        "name": "obesity_code ",
        "category": "Code Samples",
        "file_path": "assets/files/main3_1741646439.R",
        "file_type": "application/octet-stream"
      },
      {
        "name": "obesity_dataset",
        "category": "Datasets",
        "file_path": "assets/files/obesity_1741646439.csv",
        "file_type": "text/csv"
      },
      {
        "name": "obesity_report",
        "category": "",
        "file_path": "assets/files/FinalDraft_1741646439.docx",
        "file_type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
      }
    ]
  }
]